{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folder = os.path.join('data', '00_dec')\n",
    "folder = os.path.join('data', '17_dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_log_file = os.path.join(folder, '17_dec_raw.txt')\n",
    "clean_log_file = os.path.join(folder, 'clean_log_dratuti.txt')\n",
    "raw_msgs_file = os.path.join(folder, 'raw_msgs.txt')\n",
    "ltrs_only_msgs_file = os.path.join(folder, 'ltrs_only_msgs.txt')\n",
    "no_stopwords_msgs_file = os.path.join(folder, 'no_stopwords_msgs.txt')\n",
    "normalized_no_stopwords_msgs_file = os.path.join(folder, 'normalized_no_stopwords_msgs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_msgs(msgs, filename):\n",
    "    with open(filename, 'w') as lf:\n",
    "        lf.write('\\n'.join([' '.join(msg) for msg in msgs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* convert to lowercase\n",
    "* remove \n",
    "    * urls\n",
    "    * mentions (start with `@`)\n",
    "    * punctuation\n",
    "    * telegram commands (start with `/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108177\n"
     ]
    }
   ],
   "source": [
    "with open(raw_log_file) as lf:\n",
    "    log = lf.readlines()\n",
    "print(len(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = list(filter(lambda line: not line.startswith('/'), log))\n",
    "\n",
    "regex_url = re.compile(r'https?://[^\\s]*')\n",
    "raw = regex_url.sub(' ', ''.join(log).lower())\n",
    "\n",
    "regex_mention = re.compile(r'[^\\w\\d]?@[\\w\\d]+[^\\w\\d]')\n",
    "raw = regex_mention.sub(' ', raw)\n",
    "\n",
    "raw = re.sub('ё', 'е', raw)\n",
    "\n",
    "raw_msgs = raw.splitlines()\n",
    "write_msgs(raw_msgs, raw_msgs_file)\n",
    "\n",
    "ltrs_str = 'abcdefghijklmnopqrstuvwxyzабвгдеёжзийклмнопрстуфхцчшщьыъэюя'\n",
    "ltrs = {l : l for l in ltrs_str}\n",
    "raw_txts = [''.join([ltrs.get(ch, ' ') for ch in txt]) for txt in raw_msgs]\n",
    "\n",
    "raw_txts = list(map(lambda txt: re.sub(' +', ' ', txt.strip()), raw_txts))\n",
    "raw_txts = list(filter(lambda txt: txt, raw_txts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell',\n",
       " 'hell']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = randint(0, len(raw_txts))\n",
    "raw_txts[i : i + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['поздравляю'],\n",
       " ['последний', 'день'],\n",
       " ['отсюда'],\n",
       " ['куда'],\n",
       " ['уже', 'не', 'уходишь']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [txt.split() for txt in raw_txts]\n",
    "write_msgs(msgs, ltrs_only_msgs_file)\n",
    "msgs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['поздравляю'],\n",
       " ['последний', 'день'],\n",
       " ['отсюда'],\n",
       " ['уходишь'],\n",
       " ['х', 'т'],\n",
       " ['чо', 'хуйня'],\n",
       " ['н', 'л', 'т'],\n",
       " ['voiceru', 'bot', 'глупый', 'глупый'],\n",
       " ['неправильный', 'запрос', 'попробуй'],\n",
       " ['работает', 'inline', 'режиме']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs_nosw = list(filter(lambda x: x, [list(filter(lambda x: x not in sw, msg)) for msg in msgs]))\n",
    "write_msgs(msgs_nosw, no_stopwords_msgs_file)\n",
    "msgs_nosw[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize words with `pymorphy2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def to_norm(word, morph_analyzer = morph):\n",
    "    if word == 'чай':\n",
    "        return word\n",
    "    \n",
    "    norm = morph.parse(word)[0].normal_form\n",
    "    \n",
    "    if norm in ['пидора', 'пидра', 'вегана']:\n",
    "        return norm[:-1]\n",
    "    \n",
    "    if norm == 'нихуй':\n",
    "        return 'нихуя'\n",
    "    \n",
    "    if norm == 'хуйль':\n",
    "        return 'хуйли'\n",
    "    \n",
    "    if norm == 'хула':\n",
    "        return 'хуле'\n",
    "    \n",
    "    if norm == 'штол':\n",
    "        return 'штоле'\n",
    "    \n",
    "    if norm == 'гея':\n",
    "        return 'гей'\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def normalize_msg(msg):\n",
    "    if type(msg) == str:\n",
    "        msg = msg.split()\n",
    "\n",
    "    for w in msg:\n",
    "        norm_w = to_norm(w)\n",
    "        yield norm_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['поздравлять'],\n",
       " ['последний', 'день'],\n",
       " ['отсюда'],\n",
       " ['уходить'],\n",
       " ['х', 'том'],\n",
       " ['чо', 'хуйня'],\n",
       " ['наш', 'литр', 'том'],\n",
       " ['voiceru', 'bot', 'глупый', 'глупый'],\n",
       " ['неправильный', 'запрос', 'попробовать'],\n",
       " ['работать', 'inline', 'режим'],\n",
       " ['общааться', 'он', 'напрямую'],\n",
       " ['тупой'],\n",
       " ['похуй', 'ключ'],\n",
       " ['текст'],\n",
       " ['хз', 'установиться'],\n",
       " ['указать',\n",
       "  'свой',\n",
       "  'ключ',\n",
       "  'yandex',\n",
       "  'speechkit',\n",
       "  'cloud',\n",
       "  'получить',\n",
       "  'адрес'],\n",
       " ['дробный', 'help'],\n",
       " ['настройка'],\n",
       " ['администратор', 'добавить', 'бот', 'valentin'],\n",
       " ['режим', 'работа', 'текст', 'речь', 'речь', 'текст'],\n",
       " ['тихий', 'режим', 'служебный', 'сообщение', 'включить'],\n",
       " ['команда', 'присылать', 'угодный'],\n",
       " ['ключ', 'yandex', 'speechkit', 'cloud', 'установленный'],\n",
       " ['голос', 'maxim'],\n",
       " ['эмоция', 'доброжелательный']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs_nosw_norm = [list(normalize_msg(msg)) for msg in msgs_nosw]\n",
    "write_msgs(msgs_nosw_norm, normalized_no_stopwords_msgs_file)\n",
    "msgs_nosw_norm[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "#                              tokenizer = None,\n",
    "#                              preprocessor = None,\n",
    "#                              stop_words = sw,\n",
    "#                              max_features = 1000)\n",
    "\n",
    "# %%time\n",
    "# data_features = vectorizer.fit_transform(text_ltrs)\n",
    "\n",
    "# feats = data_features.toarray()\n",
    "\n",
    "# sum(sum(feats))\n",
    "\n",
    "# vectorizer.get_feature_names()[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
