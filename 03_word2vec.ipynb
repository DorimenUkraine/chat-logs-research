{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_folder = os.path.join('data', '00_dec')\n",
    "data_folder = os.path.join('data', '17_dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_folder = 'w2v_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_log_file = os.path.join(data_folder, 'log_dratuti.txt')\n",
    "clean_log_file = os.path.join(data_folder, 'clean_log_dratuti.txt')\n",
    "raw_msgs_file = os.path.join(data_folder, 'raw_msgs.txt')\n",
    "ltrs_only_msgs_file = os.path.join(data_folder, 'ltrs_only_msgs.txt')\n",
    "no_stopwords_msgs_file = os.path.join(data_folder, 'no_stopwords_msgs.txt')\n",
    "normalized_no_stopwords_msgs_file = os.path.join(data_folder, 'normalized_no_stopwords_msgs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_msgs(msgs, filename):\n",
    "    with open(filename, 'w') as lf:\n",
    "        lf.write('\\n'.join([' '.join(msg) for msg in msgs]))\n",
    "def read_msgs(filename):\n",
    "    with open(filename) as lf:\n",
    "        msgs = [line.split() for line in lf.readlines()]\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_similar_words(words, model):\n",
    "    for w in words:\n",
    "        print('--- ' + w + ' ---')\n",
    "        for sim_w in model.similar_by_word(w):\n",
    "            print('{} ({})'.format(sim_w[0], round(sim_w[1], 4)))\n",
    "            # print(sim_w[0])\n",
    "        print()\n",
    "\n",
    "test_words_1 = ['пидор', 'хуй', 'тупка', 'wtf', 'няшка']\n",
    "test_words_names = ['валентин', 'юра', 'тимофей']\n",
    "test_words_synon = ['пидор', 'пидр', 'гей']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msgs = read_msgs(ltrs_only_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8504, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model = word2vec.Word2Vec(msgs, \n",
    "                          workers = num_workers, \n",
    "                          size = num_features, \n",
    "                          min_count = min_word_count,\n",
    "                          window = context, \n",
    "                          sample = downsampling)\n",
    "\n",
    "\n",
    "model.save(os.path.join(word2vec_folder, 'model_w2v'))\n",
    "print(model.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "виктор (0.9897)\n",
      "заебал (0.9784)\n",
      "вербов (0.9741)\n",
      "ниоч (0.9727)\n",
      "котейка (0.9722)\n",
      "борис (0.9717)\n",
      "солнышко (0.9714)\n",
      "расскажи (0.9682)\n",
      "инфа (0.9643)\n",
      "баг (0.9626)\n",
      "\n",
      "--- хуй ---\n",
      "вопрос (0.9435)\n",
      "сука (0.9264)\n",
      "денег (0.9182)\n",
      "уж (0.9176)\n",
      "ней (0.9143)\n",
      "пишешь (0.9141)\n",
      "грамматику (0.9124)\n",
      "нормально (0.9108)\n",
      "мой (0.91)\n",
      "бонусы (0.9084)\n",
      "\n",
      "--- тупка ---\n",
      "аня (0.9368)\n",
      "няшка (0.9348)\n",
      "тимофей (0.8865)\n",
      "споки (0.8811)\n",
      "поговорите (0.88)\n",
      "юра (0.8773)\n",
      "солнышко (0.8772)\n",
      "сучка (0.8746)\n",
      "валентин (0.8746)\n",
      "иисусе (0.8741)\n",
      "\n",
      "--- wtf ---\n",
      "mp (0.993)\n",
      "root (0.9925)\n",
      "lets (0.9917)\n",
      "button (0.9916)\n",
      "post (0.9915)\n",
      "module (0.9915)\n",
      "law (0.9913)\n",
      "media (0.9912)\n",
      "option (0.991)\n",
      "things (0.9909)\n",
      "\n",
      "--- няшка ---\n",
      "тимофей (0.963)\n",
      "дерзкий (0.9606)\n",
      "босс (0.9527)\n",
      "грубый (0.9505)\n",
      "ах (0.949)\n",
      "находишь (0.9445)\n",
      "слишком (0.9392)\n",
      "споки (0.939)\n",
      "борис (0.9369)\n",
      "любишь (0.9366)\n",
      "\n",
      "--- валентин ---\n",
      "бооом (0.9826)\n",
      "эй (0.9747)\n",
      "транс (0.9745)\n",
      "прекращай (0.9737)\n",
      "манда (0.9691)\n",
      "крашеная (0.9686)\n",
      "велик (0.9677)\n",
      "трактор (0.963)\n",
      "оригинальный (0.9624)\n",
      "подчиняется (0.9604)\n",
      "\n",
      "--- юра ---\n",
      "тимофей (0.9096)\n",
      "аня (0.892)\n",
      "катя (0.8892)\n",
      "няшка (0.8863)\n",
      "валя (0.8775)\n",
      "тупка (0.8773)\n",
      "боря (0.8425)\n",
      "трап (0.8402)\n",
      "ах (0.8359)\n",
      "кот (0.8347)\n",
      "\n",
      "--- тимофей ---\n",
      "валя (0.9759)\n",
      "любишь (0.9652)\n",
      "ах (0.9645)\n",
      "боря (0.9637)\n",
      "няшка (0.963)\n",
      "скажи (0.9459)\n",
      "опять (0.9427)\n",
      "катя (0.9387)\n",
      "босс (0.9368)\n",
      "тим (0.9352)\n",
      "\n",
      "--- пидор ---\n",
      "виктор (0.9897)\n",
      "заебал (0.9784)\n",
      "вербов (0.9741)\n",
      "ниоч (0.9727)\n",
      "котейка (0.9722)\n",
      "борис (0.9717)\n",
      "солнышко (0.9714)\n",
      "расскажи (0.9682)\n",
      "инфа (0.9643)\n",
      "баг (0.9626)\n",
      "\n",
      "--- пидр ---\n",
      "хотите (0.9846)\n",
      "выучить (0.9827)\n",
      "размера (0.9825)\n",
      "сонечка (0.9824)\n",
      "точнее (0.9818)\n",
      "учите (0.9811)\n",
      "воп (0.9807)\n",
      "вероятно (0.9803)\n",
      "царски (0.98)\n",
      "сосиски (0.9795)\n",
      "\n",
      "--- гей ---\n",
      "пробовал (0.9829)\n",
      "слушаешь (0.9796)\n",
      "напишешь (0.9769)\n",
      "прав (0.9744)\n",
      "секси (0.9735)\n",
      "спишь (0.9729)\n",
      "тупой (0.9648)\n",
      "чето (0.9635)\n",
      "валь (0.9629)\n",
      "дотер (0.9625)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(test_words_1, model)\n",
    "print_similar_words(test_words_names, model)\n",
    "print_similar_words(test_words_synon, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msgs_nosw = read_msgs(no_stopwords_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8353, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model_nosw = word2vec.Word2Vec(msgs_nosw, \n",
    "                                workers = num_workers, \n",
    "                                size = num_features, \n",
    "                                min_count = min_word_count,\n",
    "                                window = context, \n",
    "                                sample = downsampling)\n",
    "\n",
    "\n",
    "model_nosw.save(os.path.join(word2vec_folder, 'model_w2v_no_stopwords'))\n",
    "print(model_nosw.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "чот (0.9998)\n",
      "хотят (0.9998)\n",
      "брать (0.9997)\n",
      "еду (0.9997)\n",
      "та (0.9996)\n",
      "хватит (0.9996)\n",
      "всем (0.9996)\n",
      "попробуй (0.9995)\n",
      "лал (0.9995)\n",
      "бесит (0.9995)\n",
      "\n",
      "--- хуй ---\n",
      "знает (0.9998)\n",
      "нужен (0.9997)\n",
      "сразу (0.9997)\n",
      "порно (0.9997)\n",
      "лишь (0.9996)\n",
      "ебать (0.9996)\n",
      "анус (0.9996)\n",
      "музыка (0.9996)\n",
      "ладно (0.9996)\n",
      "какие (0.9996)\n",
      "\n",
      "--- тупка ---\n",
      "няшка (0.9993)\n",
      "мид (0.9988)\n",
      "шеф (0.9987)\n",
      "катя (0.9981)\n",
      "помоги (0.998)\n",
      "магаз (0.9976)\n",
      "голубцов (0.9976)\n",
      "игрок (0.9975)\n",
      "секси (0.9974)\n",
      "поехавший (0.9971)\n",
      "\n",
      "--- wtf ---\n",
      "scala (0.9997)\n",
      "go (0.9996)\n",
      "errors (0.9996)\n",
      "already (0.9995)\n",
      "person (0.9995)\n",
      "author (0.9995)\n",
      "insert (0.9995)\n",
      "html (0.9994)\n",
      "black (0.9994)\n",
      "null (0.9994)\n",
      "\n",
      "--- няшка ---\n",
      "мид (0.9994)\n",
      "тупка (0.9993)\n",
      "шеф (0.9991)\n",
      "катя (0.9987)\n",
      "помоги (0.9986)\n",
      "кушать (0.9982)\n",
      "geekbrains (0.998)\n",
      "секси (0.998)\n",
      "голубцов (0.998)\n",
      "игрок (0.9979)\n",
      "\n",
      "--- валентин ---\n",
      "иван (0.9997)\n",
      "бар (0.9995)\n",
      "пятницу (0.9995)\n",
      "субботу (0.9995)\n",
      "думает (0.9994)\n",
      "тобой (0.9994)\n",
      "обладает (0.9994)\n",
      "твоей (0.9994)\n",
      "дай (0.9993)\n",
      "мной (0.9993)\n",
      "\n",
      "--- юра ---\n",
      "вчерашний (0.9944)\n",
      "бом (0.9848)\n",
      "опущен (0.9839)\n",
      "манда (0.9787)\n",
      "бооом (0.9783)\n",
      "опускать (0.9672)\n",
      "бильярд (0.9612)\n",
      "пст (0.9604)\n",
      "прекращай (0.9581)\n",
      "голубцы (0.9531)\n",
      "\n",
      "--- тимофей ---\n",
      "делает (0.9999)\n",
      "заебал (0.9999)\n",
      "виктор (0.9999)\n",
      "ой (0.9998)\n",
      "аня (0.9997)\n",
      "пизда (0.9997)\n",
      "скажешь (0.9997)\n",
      "босс (0.9996)\n",
      "дам (0.9996)\n",
      "играет (0.9996)\n",
      "\n",
      "--- пидор ---\n",
      "чот (0.9998)\n",
      "хотят (0.9998)\n",
      "брать (0.9997)\n",
      "еду (0.9997)\n",
      "та (0.9996)\n",
      "хватит (0.9996)\n",
      "всем (0.9996)\n",
      "попробуй (0.9995)\n",
      "лал (0.9995)\n",
      "бесит (0.9995)\n",
      "\n",
      "--- пидр ---\n",
      "хуле (0.9991)\n",
      "конец (0.9991)\n",
      "которую (0.9991)\n",
      "ща (0.9991)\n",
      "тока (0.9991)\n",
      "мужик (0.9991)\n",
      "бота (0.999)\n",
      "офис (0.999)\n",
      "походу (0.999)\n",
      "снова (0.999)\n",
      "\n",
      "--- гей ---\n",
      "жизнь (0.9999)\n",
      "собой (0.9999)\n",
      "говорят (0.9999)\n",
      "рядом (0.9999)\n",
      "против (0.9999)\n",
      "жаль (0.9999)\n",
      "скоро (0.9999)\n",
      "свой (0.9999)\n",
      "своего (0.9999)\n",
      "поезд (0.9999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(test_words_1, model_nosw)\n",
    "print_similar_words(test_words_names, model_nosw)\n",
    "print_similar_words(test_words_synon, model_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized with `pymorphy2`, no stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def to_norm(word, morph_analyzer = morph):\n",
    "    if word == 'чай':\n",
    "        return word\n",
    "    \n",
    "    norm = morph.parse(word)[0].normal_form\n",
    "    \n",
    "    if norm in ['пидора', 'пидра', 'вегана']:\n",
    "        return norm[:-1]\n",
    "    \n",
    "    if norm == 'нихуй':\n",
    "        return 'нихуя'\n",
    "    \n",
    "    if norm == 'хуйль':\n",
    "        return 'хуйли'\n",
    "    \n",
    "    if norm == 'хула':\n",
    "        return 'хуле'\n",
    "    \n",
    "    if norm == 'штол':\n",
    "        return 'штоле'\n",
    "    \n",
    "    if norm == 'гея':\n",
    "        return 'гей'\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def normalize_msg(msg):\n",
    "    if type(msg) == str:\n",
    "        msg = msg.split()\n",
    "\n",
    "    for w in msg:\n",
    "        norm_w = to_norm(w)\n",
    "        yield norm_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgs_nosw_norm = read_msgs(normalized_no_stopwords_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7141, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model_nosw_norm = word2vec.Word2Vec(msgs_nosw_norm, \n",
    "                                     workers = num_workers, \n",
    "                                     size = num_features, \n",
    "                                     min_count = min_word_count,\n",
    "                                     window = context, \n",
    "                                     sample = downsampling)\n",
    "\n",
    "\n",
    "model_nosw_norm.save(os.path.join(word2vec_folder, 'model_w2v_nosw_norm'))\n",
    "print(model_nosw_norm.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "чатик (0.9997)\n",
      "чот (0.9994)\n",
      "телеграм (0.9994)\n",
      "блядь (0.9992)\n",
      "сиг (0.9992)\n",
      "орать (0.9992)\n",
      "хуйн (0.9992)\n",
      "котейка (0.9992)\n",
      "пофига (0.9992)\n",
      "ща (0.9991)\n",
      "\n",
      "--- хуй ---\n",
      "нравиться (0.999)\n",
      "интересно (0.9989)\n",
      "жить (0.9989)\n",
      "никто (0.9988)\n",
      "видеть (0.9988)\n",
      "твой (0.9988)\n",
      "норма (0.9986)\n",
      "лола (0.9986)\n",
      "обсуждать (0.9985)\n",
      "написать (0.9984)\n",
      "\n",
      "--- тупка ---\n",
      "плз (0.9993)\n",
      "кончиться (0.9991)\n",
      "магаз (0.9991)\n",
      "кот (0.9991)\n",
      "дот (0.9991)\n",
      "кушать (0.9991)\n",
      "игрок (0.999)\n",
      "бухать (0.999)\n",
      "конф (0.999)\n",
      "покер (0.999)\n",
      "\n",
      "--- wtf ---\n",
      "oh (0.9997)\n",
      "scala (0.9997)\n",
      "already (0.9996)\n",
      "private (0.9996)\n",
      "data (0.9996)\n",
      "go (0.9995)\n",
      "times (0.9995)\n",
      "idea (0.9995)\n",
      "high (0.9995)\n",
      "bn (0.9995)\n",
      "\n",
      "--- няшка ---\n",
      "голубец (0.9997)\n",
      "шеф (0.9997)\n",
      "бомж (0.9996)\n",
      "опустить (0.9995)\n",
      "отпиздить (0.9995)\n",
      "мид (0.9995)\n",
      "косарь (0.9994)\n",
      "форсить (0.9994)\n",
      "бухать (0.9993)\n",
      "дот (0.9993)\n",
      "\n",
      "--- валентин ---\n",
      "гриб (0.9996)\n",
      "пивко (0.9995)\n",
      "продаваться (0.9995)\n",
      "борис (0.9995)\n",
      "бить (0.9995)\n",
      "йо (0.9995)\n",
      "мороженое (0.9995)\n",
      "утром (0.9995)\n",
      "гайза (0.9995)\n",
      "гулять (0.9994)\n",
      "\n",
      "--- юра ---\n",
      "бом (0.9732)\n",
      "манда (0.9579)\n",
      "бооом (0.9556)\n",
      "канешн (0.9381)\n",
      "го (0.9363)\n",
      "бильярд (0.9332)\n",
      "shizoid (0.9255)\n",
      "сабвеять (0.9225)\n",
      "пегий (0.9112)\n",
      "прекращать (0.9027)\n",
      "\n",
      "--- тимофей ---\n",
      "рассказать (0.9998)\n",
      "заебал (0.9996)\n",
      "научить (0.9994)\n",
      "питон (0.9994)\n",
      "мутить (0.9993)\n",
      "дима (0.9992)\n",
      "боря (0.9991)\n",
      "geekbrains (0.9991)\n",
      "виктор (0.999)\n",
      "потыкать (0.999)\n",
      "\n",
      "--- пидор ---\n",
      "чатик (0.9997)\n",
      "чот (0.9994)\n",
      "телеграм (0.9994)\n",
      "блядь (0.9992)\n",
      "сиг (0.9992)\n",
      "орать (0.9992)\n",
      "хуйн (0.9992)\n",
      "котейка (0.9992)\n",
      "пофига (0.9992)\n",
      "ща (0.9991)\n",
      "\n",
      "--- пидр ---\n",
      "наркоман (0.9997)\n",
      "поехать (0.9997)\n",
      "скоро (0.9997)\n",
      "хуйли (0.9997)\n",
      "заестись (0.9997)\n",
      "получиться (0.9997)\n",
      "погромист (0.9997)\n",
      "напомнить (0.9997)\n",
      "живой (0.9997)\n",
      "обед (0.9997)\n",
      "\n",
      "--- гей ---\n",
      "товарищ (0.9999)\n",
      "бывать (0.9999)\n",
      "кухня (0.9999)\n",
      "путин (0.9999)\n",
      "збс (0.9999)\n",
      "запилить (0.9999)\n",
      "напомнить (0.9999)\n",
      "оригинальный (0.9999)\n",
      "гитхаб (0.9999)\n",
      "особенно (0.9999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(list(map(to_norm, test_words_1)), model_nosw_norm)\n",
    "print_similar_words(list(map(to_norm, test_words_names)), model_nosw_norm)\n",
    "print_similar_words(list(map(to_norm, test_words_synon)), model_nosw_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messages with words from the last `w2v` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79307\n",
      "75338\n",
      "75338\n"
     ]
    }
   ],
   "source": [
    "print(len(msgs))\n",
    "print(len(msgs_nosw))\n",
    "print(len(msgs_nosw_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7141\n"
     ]
    }
   ],
   "source": [
    "ws = list(model_nosw_norm.vocab.keys())\n",
    "print(len(ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# msgs_with_popular = list(set([(sum(w in ws for w in msg)*100//len(msg), ' '.join(msg)) for msg in msgs_nosw_norm]))\n",
    "\n",
    "msgs_with_popular = list(set([(sum(w in ws for w in msg)*100//len(msg), ' '.join(msg)) for msg in msgs_nosw_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgs_with_popular.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# msgs_with_popular[:20]\n",
    "\n",
    "# msgs_with_popular[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "#                              tokenizer = None,\n",
    "#                              preprocessor = None,\n",
    "#                              stop_words = sw,\n",
    "#                              max_features = 1000)\n",
    "\n",
    "# %%time\n",
    "# data_features = vectorizer.fit_transform(text_ltrs)\n",
    "\n",
    "# feats = data_features.toarray()\n",
    "\n",
    "# sum(sum(feats))\n",
    "\n",
    "# vectorizer.get_feature_names()[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
