{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katya/anaconda3/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_folder = os.path.join('data', '00_dec')\n",
    "data_folder = os.path.join('data', '17_dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_folder = 'w2v_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_log_file = os.path.join(data_folder, 'log_dratuti.txt')\n",
    "clean_log_file = os.path.join(data_folder, 'clean_log_dratuti.txt')\n",
    "raw_msgs_file = os.path.join(data_folder, 'raw_msgs.txt')\n",
    "ltrs_only_msgs_file = os.path.join(data_folder, 'ltrs_only_msgs.txt')\n",
    "no_stopwords_msgs_file = os.path.join(data_folder, 'no_stopwords_msgs.txt')\n",
    "normalized_no_stopwords_msgs_file = os.path.join(data_folder, 'normalized_no_stopwords_msgs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_msgs(msgs, filename):\n",
    "    with open(filename, 'w') as lf:\n",
    "        lf.write('\\n'.join([' '.join(msg) for msg in msgs]))\n",
    "def read_msgs(filename):\n",
    "    with open(filename) as lf:\n",
    "        msgs = [line.split() for line in lf.readlines()]\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_similar_words(words, model):\n",
    "    for w in words:\n",
    "        print('--- ' + w + ' ---')\n",
    "        for sim_w in model.similar_by_word(w):\n",
    "            print('{} ({})'.format(sim_w[0], round(sim_w[1], 4)))\n",
    "            # print(sim_w[0])\n",
    "        print()\n",
    "\n",
    "test_words_1 = ['пидор', 'хуй', 'тупка', 'wtf', 'няшка']\n",
    "test_words_names = ['валентин', 'юра', 'тимофей']\n",
    "test_words_synon = ['пидор', 'пидр', 'гей']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msgs = read_msgs(ltrs_only_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8504, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model = word2vec.Word2Vec(msgs, \n",
    "                          workers = num_workers, \n",
    "                          size = num_features, \n",
    "                          min_count = min_word_count,\n",
    "                          window = context, \n",
    "                          sample = downsampling)\n",
    "\n",
    "\n",
    "model.save(os.path.join(word2vec_folder, 'model_w2v'))\n",
    "print(model.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "виктор (0.9833)\n",
      "борис (0.9828)\n",
      "вербов (0.9733)\n",
      "кончился (0.9727)\n",
      "ниоч (0.9714)\n",
      "котейка (0.97)\n",
      "заебал (0.969)\n",
      "расскажи (0.9688)\n",
      "крч (0.9658)\n",
      "слыш (0.9643)\n",
      "\n",
      "--- хуй ---\n",
      "сука (0.9302)\n",
      "ясно (0.9161)\n",
      "такими (0.913)\n",
      "фильм (0.9128)\n",
      "юру (0.9057)\n",
      "нормально (0.9054)\n",
      "джс (0.9048)\n",
      "субтитрами (0.9047)\n",
      "вопрос (0.9024)\n",
      "сиди (0.9006)\n",
      "\n",
      "--- тупка ---\n",
      "аня (0.9226)\n",
      "няшка (0.9199)\n",
      "раздобыл (0.902)\n",
      "иисусе (0.8854)\n",
      "христе (0.879)\n",
      "господе (0.876)\n",
      "споки (0.8746)\n",
      "сучка (0.8726)\n",
      "тимофей (0.8715)\n",
      "трап (0.8715)\n",
      "\n",
      "--- wtf ---\n",
      "link (0.9887)\n",
      "option (0.9877)\n",
      "access (0.987)\n",
      "package (0.9862)\n",
      "russian (0.9861)\n",
      "profile (0.9857)\n",
      "things (0.9855)\n",
      "ask (0.9848)\n",
      "tab (0.9844)\n",
      "okpdname (0.9844)\n",
      "\n",
      "--- няшка ---\n",
      "ах (0.9648)\n",
      "тимофей (0.964)\n",
      "раздобыл (0.9499)\n",
      "босс (0.9478)\n",
      "борис (0.9412)\n",
      "молодец (0.941)\n",
      "грубый (0.9384)\n",
      "дерзкий (0.9369)\n",
      "любишь (0.9347)\n",
      "иисусе (0.9329)\n",
      "\n",
      "--- валентин ---\n",
      "бооом (0.9728)\n",
      "манда (0.9673)\n",
      "оригинальный (0.9651)\n",
      "прекращай (0.9645)\n",
      "крашеная (0.9609)\n",
      "пст (0.96)\n",
      "велик (0.9593)\n",
      "фронтендер (0.955)\n",
      "игрок (0.9545)\n",
      "пиу (0.9539)\n",
      "\n",
      "--- юра ---\n",
      "тимофей (0.8987)\n",
      "аня (0.8828)\n",
      "катя (0.8806)\n",
      "валя (0.8674)\n",
      "няшка (0.8552)\n",
      "тупка (0.8291)\n",
      "виктор (0.8227)\n",
      "дерзкий (0.8166)\n",
      "кот (0.8126)\n",
      "боря (0.8117)\n",
      "\n",
      "--- тимофей ---\n",
      "няшка (0.964)\n",
      "валя (0.962)\n",
      "любишь (0.9558)\n",
      "боря (0.9444)\n",
      "ах (0.9439)\n",
      "скажи (0.9325)\n",
      "тим (0.9268)\n",
      "молодец (0.9256)\n",
      "босс (0.9249)\n",
      "заебал (0.9225)\n",
      "\n",
      "--- пидор ---\n",
      "виктор (0.9833)\n",
      "борис (0.9828)\n",
      "вербов (0.9733)\n",
      "кончился (0.9727)\n",
      "ниоч (0.9714)\n",
      "котейка (0.97)\n",
      "заебал (0.969)\n",
      "расскажи (0.9688)\n",
      "крч (0.9658)\n",
      "слыш (0.9643)\n",
      "\n",
      "--- пидр ---\n",
      "вероятно (0.9801)\n",
      "серия (0.9798)\n",
      "погромисты (0.9791)\n",
      "емнип (0.9783)\n",
      "рекомендую (0.9779)\n",
      "настало (0.9763)\n",
      "кружки (0.9753)\n",
      "приложения (0.9752)\n",
      "лаффки (0.9749)\n",
      "чтоле (0.9745)\n",
      "\n",
      "--- гей ---\n",
      "слушаешь (0.9753)\n",
      "пробовал (0.974)\n",
      "прав (0.9707)\n",
      "напишешь (0.9672)\n",
      "бедный (0.9649)\n",
      "отдал (0.964)\n",
      "спишь (0.9627)\n",
      "перестанет (0.9621)\n",
      "таким (0.9604)\n",
      "епта (0.9574)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(test_words_1, model)\n",
    "print_similar_words(test_words_names, model)\n",
    "print_similar_words(test_words_synon, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msgs_nosw = read_msgs(no_stopwords_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8353, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model_nosw = word2vec.Word2Vec(msgs_nosw, \n",
    "                                workers = num_workers, \n",
    "                                size = num_features, \n",
    "                                min_count = min_word_count,\n",
    "                                window = context, \n",
    "                                sample = downsampling)\n",
    "\n",
    "\n",
    "model_nosw.save(os.path.join(word2vec_folder, 'model_w2v_no_stopwords'))\n",
    "print(model_nosw.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "та (0.9996)\n",
      "бесит (0.9995)\n",
      "еду (0.9995)\n",
      "всем (0.9995)\n",
      "хватит (0.9995)\n",
      "сначала (0.9995)\n",
      "голос (0.9994)\n",
      "кого (0.9994)\n",
      "имхо (0.9994)\n",
      "делал (0.9994)\n",
      "\n",
      "--- хуй ---\n",
      "будешь (0.9998)\n",
      "прям (0.9997)\n",
      "пхп (0.9997)\n",
      "буду (0.9997)\n",
      "говорит (0.9997)\n",
      "поняла (0.9997)\n",
      "те (0.9997)\n",
      "чота (0.9996)\n",
      "написал (0.9996)\n",
      "сегодня (0.9996)\n",
      "\n",
      "--- тупка ---\n",
      "бухать (0.999)\n",
      "говном (0.999)\n",
      "кофе (0.9989)\n",
      "магаз (0.9988)\n",
      "сделаем (0.9988)\n",
      "умеешь (0.9987)\n",
      "няшка (0.9987)\n",
      "ебет (0.9987)\n",
      "тимофей (0.9987)\n",
      "пивка (0.9987)\n",
      "\n",
      "--- wtf ---\n",
      "sum (0.9997)\n",
      "chrome (0.9996)\n",
      "html (0.9996)\n",
      "javascript (0.9996)\n",
      "void (0.9996)\n",
      "php (0.9996)\n",
      "lastname (0.9996)\n",
      "университета (0.9996)\n",
      "row (0.9995)\n",
      "борисов (0.9995)\n",
      "\n",
      "--- няшка ---\n",
      "шеф (0.9998)\n",
      "катя (0.9995)\n",
      "конфу (0.9994)\n",
      "кофе (0.9992)\n",
      "валя (0.9991)\n",
      "поехавший (0.9991)\n",
      "голубцов (0.999)\n",
      "тупка (0.9987)\n",
      "магаз (0.9986)\n",
      "помоги (0.9986)\n",
      "\n",
      "--- валентин ---\n",
      "иван (0.9998)\n",
      "бар (0.9998)\n",
      "субботу (0.9997)\n",
      "дай (0.9997)\n",
      "косарь (0.9997)\n",
      "эй (0.9997)\n",
      "мной (0.9996)\n",
      "тима (0.9996)\n",
      "любит (0.9996)\n",
      "питоне (0.9996)\n",
      "\n",
      "--- юра ---\n",
      "бооом (0.9904)\n",
      "бом (0.988)\n",
      "опущен (0.9833)\n",
      "вчерашний (0.983)\n",
      "прекращай (0.9806)\n",
      "опускать (0.9784)\n",
      "пвп (0.9755)\n",
      "пст (0.9714)\n",
      "бедный (0.9687)\n",
      "shizoid (0.9672)\n",
      "\n",
      "--- тимофей ---\n",
      "заебал (0.9998)\n",
      "аня (0.9997)\n",
      "хочешь (0.9997)\n",
      "виктор (0.9996)\n",
      "бухать (0.9996)\n",
      "пизда (0.9996)\n",
      "синяков (0.9996)\n",
      "видишь (0.9996)\n",
      "дам (0.9996)\n",
      "говном (0.9996)\n",
      "\n",
      "--- пидор ---\n",
      "та (0.9996)\n",
      "бесит (0.9995)\n",
      "еду (0.9995)\n",
      "всем (0.9995)\n",
      "хватит (0.9995)\n",
      "сначала (0.9995)\n",
      "голос (0.9994)\n",
      "кого (0.9994)\n",
      "имхо (0.9994)\n",
      "делал (0.9994)\n",
      "\n",
      "--- пидр ---\n",
      "боря (0.9988)\n",
      "давай (0.9988)\n",
      "весь (0.9987)\n",
      "молодец (0.9987)\n",
      "чатик (0.9987)\n",
      "жрать (0.9987)\n",
      "сука (0.9987)\n",
      "борис (0.9987)\n",
      "могу (0.9987)\n",
      "нам (0.9987)\n",
      "\n",
      "--- гей ---\n",
      "умеет (0.9999)\n",
      "нужна (0.9999)\n",
      "своего (0.9999)\n",
      "жаль (0.9999)\n",
      "второй (0.9998)\n",
      "ними (0.9998)\n",
      "собой (0.9998)\n",
      "особенно (0.9998)\n",
      "адвмейкер (0.9998)\n",
      "третий (0.9998)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(test_words_1, model_nosw)\n",
    "print_similar_words(test_words_names, model_nosw)\n",
    "print_similar_words(test_words_synon, model_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized with `pymorphy2`, no stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def to_norm(word, morph_analyzer = morph):\n",
    "    if word == 'чай':\n",
    "        return word\n",
    "    \n",
    "    norm = morph.parse(word)[0].normal_form\n",
    "    \n",
    "    if norm in ['пидора', 'пидра', 'вегана']:\n",
    "        return norm[:-1]\n",
    "    \n",
    "    if norm == 'нихуй':\n",
    "        return 'нихуя'\n",
    "    \n",
    "    if norm == 'хуйль':\n",
    "        return 'хуйли'\n",
    "    \n",
    "    if norm == 'хула':\n",
    "        return 'хуле'\n",
    "    \n",
    "    if norm == 'штол':\n",
    "        return 'штоле'\n",
    "    \n",
    "    if norm == 'гея':\n",
    "        return 'гей'\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def normalize_msg(msg):\n",
    "    if type(msg) == str:\n",
    "        msg = msg.split()\n",
    "\n",
    "    for w in msg:\n",
    "        norm_w = to_norm(w)\n",
    "        yield norm_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgs_nosw_norm = read_msgs(normalized_no_stopwords_msgs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7141, 300)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 5   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10           # Context window size\n",
    "downsampling = 0.5   # Downsample setting for frequent words\n",
    "\n",
    "model_nosw_norm = word2vec.Word2Vec(msgs_nosw_norm, \n",
    "                                     workers = num_workers, \n",
    "                                     size = num_features, \n",
    "                                     min_count = min_word_count,\n",
    "                                     window = context, \n",
    "                                     sample = downsampling)\n",
    "\n",
    "\n",
    "model_nosw_norm.save(os.path.join(word2vec_folder, 'model_w2v_nosw_norm'))\n",
    "print(model_nosw_norm.syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- пидор ---\n",
      "сходить (0.9997)\n",
      "еда (0.9997)\n",
      "чот (0.9996)\n",
      "голос (0.9994)\n",
      "хватить (0.9994)\n",
      "поехать (0.9994)\n",
      "приветик (0.9994)\n",
      "кухня (0.9993)\n",
      "решить (0.9993)\n",
      "метро (0.9993)\n",
      "\n",
      "--- хуй ---\n",
      "нравиться (0.999)\n",
      "блять (0.999)\n",
      "обсуждать (0.9989)\n",
      "интересно (0.9988)\n",
      "твой (0.9987)\n",
      "бля (0.9987)\n",
      "знаешь (0.9985)\n",
      "норма (0.9981)\n",
      "играть (0.9981)\n",
      "понимать (0.9981)\n",
      "\n",
      "--- тупка ---\n",
      "позвать (0.9994)\n",
      "плз (0.9993)\n",
      "обижать (0.9993)\n",
      "иван (0.9993)\n",
      "максим (0.9992)\n",
      "продать (0.9992)\n",
      "магаз (0.9992)\n",
      "пятница (0.9992)\n",
      "кофе (0.9992)\n",
      "фу (0.9991)\n",
      "\n",
      "--- wtf ---\n",
      "go (0.9997)\n",
      "db (0.9997)\n",
      "amount (0.9997)\n",
      "row (0.9997)\n",
      "sum (0.9997)\n",
      "black (0.9996)\n",
      "date (0.9996)\n",
      "cu (0.9996)\n",
      "location (0.9996)\n",
      "false (0.9996)\n",
      "\n",
      "--- няшка ---\n",
      "шеф (0.9997)\n",
      "косарь (0.9997)\n",
      "опустить (0.9995)\n",
      "мид (0.9995)\n",
      "бомж (0.9994)\n",
      "отпиздить (0.9994)\n",
      "голубец (0.9994)\n",
      "кончиться (0.9994)\n",
      "дот (0.9993)\n",
      "покер (0.9993)\n",
      "\n",
      "--- валентин ---\n",
      "пожаловаться (0.9997)\n",
      "анекдот (0.9997)\n",
      "сентябрь (0.9996)\n",
      "держава (0.9996)\n",
      "йо (0.9996)\n",
      "нить (0.9996)\n",
      "продаваться (0.9996)\n",
      "пивко (0.9995)\n",
      "мокрый (0.9995)\n",
      "отдать (0.9995)\n",
      "\n",
      "--- юра ---\n",
      "бом (0.9846)\n",
      "бооом (0.9627)\n",
      "манда (0.9612)\n",
      "го (0.9462)\n",
      "канешн (0.9295)\n",
      "пофик (0.9269)\n",
      "бильярд (0.9243)\n",
      "прекращать (0.9189)\n",
      "опускать (0.9183)\n",
      "пвп (0.9169)\n",
      "\n",
      "--- тимофей ---\n",
      "заебал (0.9998)\n",
      "рассказать (0.9997)\n",
      "конф (0.9997)\n",
      "научить (0.9995)\n",
      "бухать (0.9995)\n",
      "питон (0.9994)\n",
      "отпиздить (0.9993)\n",
      "дима (0.9993)\n",
      "дот (0.9992)\n",
      "курить (0.9992)\n",
      "\n",
      "--- пидор ---\n",
      "сходить (0.9997)\n",
      "еда (0.9997)\n",
      "чот (0.9996)\n",
      "голос (0.9994)\n",
      "хватить (0.9994)\n",
      "поехать (0.9994)\n",
      "приветик (0.9994)\n",
      "кухня (0.9993)\n",
      "решить (0.9993)\n",
      "метро (0.9993)\n",
      "\n",
      "--- пидр ---\n",
      "интересоваться (0.9996)\n",
      "звать (0.9995)\n",
      "шизоид (0.9995)\n",
      "суббота (0.9995)\n",
      "глупый (0.9995)\n",
      "завести (0.9995)\n",
      "чят (0.9995)\n",
      "полина (0.9994)\n",
      "следующий (0.9994)\n",
      "хуйли (0.9994)\n",
      "\n",
      "--- гей ---\n",
      "скайп (0.9999)\n",
      "питер (0.9999)\n",
      "спасибо (0.9999)\n",
      "валить (0.9999)\n",
      "рисовать (0.9999)\n",
      "збс (0.9999)\n",
      "короче (0.9999)\n",
      "бояться (0.9999)\n",
      "ебал (0.9999)\n",
      "пилить (0.9999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_similar_words(list(map(to_norm, test_words_1)), model_nosw_norm)\n",
    "print_similar_words(list(map(to_norm, test_words_names)), model_nosw_norm)\n",
    "print_similar_words(list(map(to_norm, test_words_synon)), model_nosw_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messages with words from the last `w2v` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79307\n",
      "75338\n",
      "75338\n"
     ]
    }
   ],
   "source": [
    "print(len(msgs))\n",
    "print(len(msgs_nosw))\n",
    "print(len(msgs_nosw_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7141\n"
     ]
    }
   ],
   "source": [
    "ws = list(model_nosw_norm.vocab.keys())\n",
    "print(len(ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# msgs_with_popular = list(set([(sum(w in ws for w in msg)*100//len(msg), ' '.join(msg)) for msg in msgs_nosw_norm]))\n",
    "\n",
    "msgs_with_popular = list(set([(sum(w in ws for w in msg)*100//len(msg), ' '.join(msg)) for msg in msgs_nosw_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgs_with_popular.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# msgs_with_popular[:20]\n",
    "\n",
    "# msgs_with_popular[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7141\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model_nosw_norm.syn0\n",
    "print(word_vectors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# n_clusters = word_vectors.shape[0] // 100\n",
    "n_clusters = word_vectors.shape[0] // 10\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = n_clusters, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 33.4 s, total: 1min 35s\n",
      "Wall time: 56.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idx = km.fit_predict(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Word / Index dictionary, mapping each vocabulary word to a cluster number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_centroid_map = dict(zip(model_nosw_norm.index2word, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cluster 0 --- \n",
      "['стричься', 'микросервис', 'граммар', 'бета', 'вайфай', 'графический', 'хохлов', 'трубка', 'билайн', 'офисный', 'скролл', 'поступать', 'стас', 'рандома', 'понятие', 'предсказать', 'подробно', 'ioc', 'подключение', 'лёша', 'желательно', 'подробность', 'предъява', 'скала', 'натурал', 'бабнуть', 'копьё', 'предпочтение', 'архитектор', 'выкатить', 'трекер', 'шляпа', 'хотяб', 'поп', 'восторг', 'процессоркомпоновкидать', 'депутат', 'посещение', 'весёлый', 'танцующий', 'жильё', 'стс', 'иной', 'удержаться', 'растение', 'начальный', 'выключать', 'пьяный', 'mr', 'казанов', 'запрещать', 'бизнесмен', 'плавать', 'миша', 'энергия', 'десяток', 'аудитория', 'аборт', 'самоубийца', 'выпуск', 'сабина', 'видеобаннер', 'чтонибыть', 'стабильность', 'злоба', 'северный', 'джавист']\n",
      "\n",
      "\n",
      "--- cluster 1 --- \n",
      "['менее', 'довольно', 'консоль', 'решение', 'сервис', 'объект', 'й', 'отдел']\n",
      "\n",
      "\n",
      "--- cluster 2 --- \n",
      "['for']\n",
      "\n",
      "\n",
      "--- cluster 3 --- \n",
      "['подросток', 'смс', 'внезапно', 'выяснить', 'предмет', 'скидка', 'конкурс', 'вагон', 'активный', 'макбук', 'говнокод', 'выпустить', 'пол', 'андроид', 'предыдущий', 'свежий', 'забрать', 'нетфликс', 'налог', 'кривой', 'рельс', 'скок', 'общество', 'преступление', 'битрикс', 'анализировать', 'однажды']\n",
      "\n",
      "\n",
      "--- cluster 4 --- \n",
      "['тип']\n",
      "\n",
      "\n",
      "--- cluster 5 --- \n",
      "['перевод', 'выпить', 'попасться', 'кровь', 'основной', 'слава', 'вещество', 'мясо', 'безопасность', 'многий', 'становиться', 'действовать']\n",
      "\n",
      "\n",
      "--- cluster 6 --- \n",
      "['with']\n",
      "\n",
      "\n",
      "--- cluster 7 --- \n",
      "['couldn', 'no']\n",
      "\n",
      "\n",
      "--- cluster 8 --- \n",
      "['затральный', 'пофик', 'xddd', 'спешить', 'псих', 'нееет', 'баловаться', 'закрыться', 'пожелать', 'яваскрипт', 'печень', 'крипот', 'навязывать', 'хддда', 'припечь', 'завершить', 'ржак', 'waaaat', 'налик']\n",
      "\n",
      "\n",
      "--- cluster 9 --- \n",
      "['пытаться', 'час', 'сколько']\n",
      "\n",
      "\n",
      "--- cluster 10 --- \n",
      "['ти', 'заставлять', 'шанс', 'дружок', 'регион', 'загрузить', 'нпм', 'июнь', 'заводить', 'интеграция', 'выделяться', 'столица', 'ядро', 'мьюзик', 'ознакомиться', 'естественно', 'десктоп', 'коты', 'варкрафт', 'линия', 'ебиться', 'графика', 'разводить', 'показатель', 'голодный', 'входной', 'спиздить', 'понадобиться', 'принадлежать', 'логика']\n",
      "\n",
      "\n",
      "--- cluster 11 --- \n",
      "['облако', 'разочаровать', 'независимый', 'слоник', 'пиздюля', 'длл', 'хавать', 'пускай', 'бок', 'сток', 'джаваскриптер', 'чуткий', 'тошный', 'плей', 'унести', 'бляяяять', 'конверт', 'трахать', 'администратор', 'популярность', 'рассылка', 'проезжать', 'геймпада', 'печенек', 'поучаствовать', 'вагинальный', 'зажить', 'дропбокс', 'подготовить', 'смска', 'заслать', 'river', 'замёрзнуть', 'хвост', 'шлепок', 'испугаться', 'дёшево', 'ган', 'овнер', 'эппстор', 'москвич', 'загнивать', 'стриминговый', 'вдвоём', 'моника', 'аду', 'вонючий', 'пиздюли', 'эффективно', 'обойти', 'печать', 'folks', 'мороженный', 'bt', 'пруф', 'щитый', 'watch', 'воот', 'elk', 'строиться', 'впилить', 'шапочка', 'железка', 'ебучаять', 'госуслуга', 'ебашут', 'абстракция', 'заразить', 'конфочки', 'будни', 'очки', 'котана', 'пермь', 'сонсоль', 'четверть', 'какола', 'полно', 'врядлить', 'окея', 'предусмотреть', 'парсить', 'твиттор', 'заряд', 'embria', 'синоним', 'пр', 'эмбрий', 'маус', 'ленинский', 'подрочить', 'обезьяна', 'недалеко', 'ботик', 'булочка', 'побеждать', 'вирус', 'ээ', 'взорваться', 'попугай', 'салат', 'похмелие', 'очистка', 'прикрепить', 'окончание', 'neo', 'дождик', 'пакетик', 'многоножка', 'раскрытый', 'тс', 'акция', 'кадр', 'веселие', 'очевидный', 'попкорн', 'нерабочий', 'деться', 'дуров', 'восстановить', 'рассказ']\n",
      "\n",
      "\n",
      "--- cluster 12 --- \n",
      "['that']\n",
      "\n",
      "\n",
      "--- cluster 13 --- \n",
      "['говно']\n",
      "\n",
      "\n",
      "--- cluster 14 --- \n",
      "['must', 'result', 'start', 'word']\n",
      "\n",
      "\n",
      "--- cluster 15 --- \n",
      "['кек']\n",
      "\n",
      "\n",
      "--- cluster 16 --- \n",
      "['юра']\n",
      "\n",
      "\n",
      "--- cluster 17 --- \n",
      "['parent']\n",
      "\n",
      "\n",
      "--- cluster 18 --- \n",
      "['рабочий', 'правильно', 'умный', 'видео']\n",
      "\n",
      "\n",
      "--- cluster 19 --- \n",
      "['пиксель', 'погромист', 'ставка', 'выучить', 'вставать', 'построить', 'явно', 'ка', 'удовольствие', 'ловить']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(20):\n",
    "    print(\"--- cluster {} --- \".format(cluster))\n",
    "\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in range(len(word_centroid_map.values())):\n",
    "        if( list(word_centroid_map.values())[i] == cluster ):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "#                              tokenizer = None,\n",
    "#                              preprocessor = None,\n",
    "#                              stop_words = sw,\n",
    "#                              max_features = 1000)\n",
    "\n",
    "# %%time\n",
    "# data_features = vectorizer.fit_transform(text_ltrs)\n",
    "\n",
    "# feats = data_features.toarray()\n",
    "\n",
    "# sum(sum(feats))\n",
    "\n",
    "# vectorizer.get_feature_names()[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
